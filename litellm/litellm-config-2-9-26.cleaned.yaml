model_list:
  - model_name: kimi-k2-thinking
    litellm_params:
      model: openai/kimi-k2-thinking
      api_base: http://kimi-k2-thinking:8001/v1
      api_key: "EMPTY"

  - model_name: qwen3-next-80b-instruct
    litellm_params:
      model: openai/qwen3-next-80b-instruct
      api_base: http://qwen3-next-80b-instruct:8001/v1
      api_key: "EMPTY"
      supports_function_calling: true
      supports_vision: false

  - model_name: qwen3-next-instruct
    litellm_params:
      model: openai/qwen3-next-instruct
      api_base: http://qwen3-next-instruct:8001/v1
      api_key: "EMPTY"
      supports_function_calling: true
      supports_vision: false

  - model_name: qwen3-coder-30b
    litellm_params:
      model: openai/qwen3-coder-30b
      api_base: http://qwen3-coder-30b:8001/v1
      api_key: "EMPTY"

  - model_name: qwen3-vl-thinking
    litellm_params:
      model: openai/qwen3-vl-thinking
      api_base: http://qwen3-vl-thinking:8001/v1
      api_key: "EMPTY"
      supports_function_calling: true
      supports_vision: true

  - model_name: phi-4-mm
    litellm_params:
      model: openai/phi-4-mm
      api_base: http://phi-4-mm:8001/v1
      api_key: "EMPTY"

  - model_name: gemma-3-vision
    litellm_params:
      model: openai/gemma-3-vision
      api_base: http://gemma-3-vision:8001/v1
      api_key: "EMPTY"

  - model_name: step-3-vl-10b
    litellm_params:
      model: openai/step-3-vl-10b
      api_base: http://step-3-vl-10b:8001/v1
      api_key: "EMPTY"

  - model_name: omni
    litellm_params:
      model: openai/qwen3-omni-instruct
      api_base: http://qwen3-omni-instruct:8001/v1
      api_key: "EMPTY"

  - model_name: glm-4-6v-flash
    litellm_params:
      model: openai/glm-4-6v-flash
      api_base: http://glm-4-6v-flash:8001/v1
      api_key: "EMPTY"

  - model_name: glm-4-7-flash
    litellm_params:
      model: openai/glm-4-7-flash
      api_base: http://glm-4-7-flash:8001/v1
      api_key: "EMPTY"

  - model_name: chandra-ocr
    litellm_params:
      model: openai/chandra-ocr
      api_base: http://chandra-ocr:8001/v1
      api_key: "EMPTY"

  - model_name: kimi-linear
    litellm_params:
      model: openai/kimi-linear
      api_base: http://kimi-linear:8001/v1
      api_key: "EMPTY"

  - model_name: kimi-vl-thinking
    litellm_params:
      model: openai/kimi-vl-thinking
      api_base: http://kimi-vl-thinking:8001/v1
      api_key: "EMPTY"
      supports_function_calling: true
      supports_vision: true

  - model_name: kimi-vl-instruct
    litellm_params:
      model: openai/kimi-vl-instruct
      api_base: http://kimi-vl-instruct:8001/v1
      api_key: "EMPTY"
      supports_vision: true

general_settings:
  master_key: os.environ/LITELLM_API_KEY
  disable_auth: true
  allow_user_auth: true
  enable_key_management: true
  database_url: os.environ/LITELLM_DATABASE_URL
  store_model_in_db: true
  use_redis_transaction_buffer: true
  allow_requests_on_db_unavailable: true

router_settings:
  redis_host: os.environ/LITELLM_REDIS_HOST
  redis_port: os.environ/LITELLM_REDIS_PORT
  routing_strategy: least-busy
  enable_pre_call_checks: true
  allowed_fails: 6
  cooldown_time: 30

litellm_settings:
  cache: true
  cache_params:
    type: redis
    host: os.environ/LITELLM_REDIS_HOST
    port: os.environ/LITELLM_REDIS_PORT
    namespace: litellm.caching.caching
    mode: default_off
    ttl: 600
  json_logs: true
  drop_params: true
  default_fallbacks: ["kimi-vl-thinking"]
  success_callback: ["langfuse"]
  failure_callback: ["sentry"]
  callbacks: ["otel"]
  service_callbacks: ["prometheus"]

  mcp_servers:
    fabric-gateway:
      url: os.environ/FABRIC_MCP_URL
      transport: http
      headers:
        Authorization: os.environ/FABRIC_MCP_AUTH
