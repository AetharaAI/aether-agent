#!/usr/bin/env python3
"""
self_modify_test.py â€” Self-Modifying Agent Strategy Merger
============================================================
Reads agent_strategy.md and research_summary.md, merges findings into
v2_strategy.md, self-modifies by appending a logging function, re-executes
itself to run the new function, and outputs self_modify_report.json.

Usage:
    python3 self_modify_test.py              # Phase 1: merge + self-modify
    python3 self_modify_test.py --phase2     # Phase 2: run appended function (auto-invoked)
"""

import hashlib
import json
import os
import re
import subprocess
import sys
from datetime import datetime, timezone

# â”€â”€ Constants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SCRIPT_PATH = os.path.abspath(__file__)
BASE_DIR = os.path.dirname(SCRIPT_PATH)
STRATEGY_PATH = os.path.join(BASE_DIR, "artifacts", "generated", "agent_strategy.md")
RESEARCH_PATH = os.path.join(BASE_DIR, "artifacts", "research_summary.md")
V2_OUTPUT_PATH = os.path.join(BASE_DIR, "artifacts", "generated", "v2_strategy.md")
REPORT_PATH = os.path.join(BASE_DIR, "artifacts", "generated", "self_modify_report.json")


# â”€â”€ Utility Functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def sha256_of_file(path: str) -> str:
    """Return full SHA-256 hex digest of a file."""
    h = hashlib.sha256()
    with open(path, "rb") as f:
        for chunk in iter(lambda: f.read(8192), b""):
            h.update(chunk)
    return h.hexdigest()


def line_count(path: str) -> int:
    """Return number of lines in a file."""
    with open(path, "r") as f:
        return sum(1 for _ in f)


def read_file(path: str) -> str:
    """Read and return file contents."""
    with open(path, "r") as f:
        return f.read()


def write_file(path: str, content: str) -> None:
    """Write content to file, creating directories as needed."""
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w") as f:
        f.write(content)


# â”€â”€ Phase 1A: Extract Coordination Patterns from agent_strategy.md â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_coordination_patterns(strategy_text: str) -> dict:
    """
    Parse agent_strategy.md and extract:
      - Communication patterns (A2A, MCP, Event-Driven)
      - Coordination models table
      - Task delegation protocol steps
      - Tool usage heuristics
      - Memory tiers
      - Failure recovery levels
    """
    patterns = {}

    # Communication patterns â€” extract bullet points from section 1.1
    comm_match = re.search(
        r"### 1\.1 Communication Patterns\s*\n(.*?)(?=\n### |\n## |\Z)",
        strategy_text, re.DOTALL
    )
    if comm_match:
        bullets = re.findall(r"- \*\*(.+?)\*\*", comm_match.group(1))
        patterns["communication_patterns"] = bullets

    # Coordination models â€” extract table rows
    coord_match = re.search(
        r"### 1\.2 Coordination Models\s*\n(.*?)(?=\n### |\n## |\Z)",
        strategy_text, re.DOTALL
    )
    if coord_match:
        rows = re.findall(
            r"\|\s*\*\*(.+?)\*\*\s*\|\s*(.+?)\s*\|\s*(.+?)\s*\|",
            coord_match.group(1)
        )
        patterns["coordination_models"] = [
            {"model": r[0], "use_case": r[1].strip(), "tradeoff": r[2].strip()}
            for r in rows
        ]

    # Task delegation steps
    deleg_match = re.search(
        r"### 1\.3 Task Delegation Protocol\s*\n(.*?)(?=\n---|\n## |\Z)",
        strategy_text, re.DOTALL
    )
    if deleg_match:
        steps = re.findall(r"\d+\.\s*\*\*(.+?)\*\*\s*(.+?)(?=\n|$)", deleg_match.group(1))
        patterns["delegation_steps"] = [
            {"agent": s[0].strip(), "action": s[1].strip()} for s in steps
        ]

    # Tool heuristics
    heur_match = re.search(
        r"### 2\.2 Tool Selection Heuristics\s*\n(.*?)(?=\n### |\n## |\Z)",
        strategy_text, re.DOTALL
    )
    if heur_match:
        heuristics = re.findall(r"\d+\.\s*\*\*(.+?)\*\*", heur_match.group(1))
        patterns["tool_heuristics"] = heuristics

    # Memory tiers
    mem_match = re.search(
        r"### 3\.1 Memory Tiers\s*\n(.*?)(?=\n### |\n## |\Z)",
        strategy_text, re.DOTALL
    )
    if mem_match:
        tiers = re.findall(r"â”‚\s+([\w\- ]+MEMORY|SCRATCHPAD|CHECKPOINT[\w ]*)\s+â”‚", mem_match.group(1))
        patterns["memory_tiers"] = [t.strip() for t in tiers]

    # Failure recovery levels
    fail_match = re.search(
        r"### 4\.2 Recovery Protocols\s*\n(.*?)(?=\n### |\n## |\Z)",
        strategy_text, re.DOTALL
    )
    if fail_match:
        levels = re.findall(r"#### (Level \d+ â€” .+)", fail_match.group(1))
        patterns["recovery_levels"] = levels

    return patterns


# â”€â”€ Phase 1B: Extract Protocols & Market Data from research_summary.md â”€â”€â”€â”€â”€â”€â”€

def extract_research_intel(research_text: str) -> dict:
    """
    Parse research_summary.md and extract:
      - Protocol names and statuses
      - Market projections
      - Architecture evolution insights
      - Key players
    """
    intel = {}

    # Protocols table
    proto_rows = re.findall(
        r"\|\s*\*\*(.+?)\*\*\s*(?:\((.+?)\))?\s*\|\s*(.+?)\s*\|\s*(.+?)\s*\|\s*(.+?)\s*\|",
        research_text
    )
    if proto_rows:
        intel["protocols"] = [
            {
                "name": r[0].strip(),
                "full_name": r[1].strip() if r[1] else r[0].strip(),
                "scope": r[2].strip(),
                "backers": r[3].strip(),
                "status": r[4].strip(),
            }
            for r in proto_rows
        ]

    # Market projections
    market_match = re.findall(
        r"\$[\d.]+[BM]\b.*?(?:by \d{4}|projected|surge)",
        research_text, re.IGNORECASE
    )
    if not market_match:
        # Fallback: grab the explicit projection line
        market_match = re.findall(r"(\$[\d.]+B.*?\d{4})", research_text)
    intel["market_projections"] = market_match if market_match else ["$7.8B â†’ $52B+ by 2030"]

    # Gartner prediction
    gartner = re.search(r"Gartner predicting (.+?)(?:\.|$)", research_text)
    if gartner:
        intel["gartner_prediction"] = gartner.group(1).strip()

    # Architecture evolution
    arch_items = re.findall(
        r"\d+\.\s*\*\*(.+?)\*\*\s*â€”\s*(.+?)(?=\n\d\.|\n\n|\Z)",
        research_text, re.DOTALL
    )
    intel["architecture_evolution"] = [
        {"pattern": a[0].strip(), "description": a[1].strip().split("\n")[0]}
        for a in arch_items[:3]
    ]

    # Key players table
    player_rows = re.findall(
        r"\|\s*(\w[\w\s]+?)\s*\|\s*(.+?)\s*\|\s*(.+?)\s*\|",
        research_text
    )
    # Filter out header/separator rows
    intel["key_players"] = [
        {"platform": p[0].strip(), "category": p[1].strip(), "strength": p[2].strip()}
        for p in player_rows
        if not p[0].strip().startswith("--") and p[0].strip() not in ("Platform", "Protocol")
    ]

    # Implications
    impl_items = re.findall(r"\d+\.\s*\*\*(.+?)\*\*\s*â€”\s*(.+?)(?=\n|$)", research_text)
    intel["implications"] = [
        {"principle": i[0].strip(), "detail": i[1].strip()} for i in impl_items
    ]

    return intel


# â”€â”€ Phase 1C: Merge into v2_strategy.md â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_v2_strategy(patterns: dict, intel: dict) -> str:
    """
    Merge v1 coordination patterns with research intelligence into an
    upgraded v2 strategy document with concrete recommendations.
    """
    now = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")

    # Build protocol table rows
    proto_rows = ""
    for p in intel.get("protocols", []):
        proto_rows += f"| **{p['name']}** ({p['full_name']}) | {p['scope']} | {p['backers']} | {p['status']} |\n"

    # Build coordination model rows
    coord_rows = ""
    for c in patterns.get("coordination_models", []):
        coord_rows += f"| **{c['model']}** | {c['use_case']} | {c['tradeoff']} |\n"

    # Build delegation steps
    deleg_lines = ""
    for i, d in enumerate(patterns.get("delegation_steps", []), 1):
        deleg_lines += f"{i}. **{d['agent']}** {d['action']}\n"

    # Build tool heuristics
    heuristic_lines = ""
    for i, h in enumerate(patterns.get("tool_heuristics", []), 1):
        heuristic_lines += f"{i}. **{h}**\n"

    # Build memory tiers
    memory_lines = ""
    for t in patterns.get("memory_tiers", []):
        memory_lines += f"  - {t}\n"

    # Build recovery levels
    recovery_lines = ""
    for r in patterns.get("recovery_levels", []):
        recovery_lines += f"  - {r}\n"

    # Build architecture evolution
    arch_lines = ""
    for a in intel.get("architecture_evolution", []):
        arch_lines += f"- **{a['pattern']}** â€” {a['description']}\n"

    # Build key players
    player_rows = ""
    for p in intel.get("key_players", []):
        player_rows += f"| {p['platform']} | {p['category']} | {p['strength']} |\n"

    # Build implications
    impl_lines = ""
    for i, imp in enumerate(intel.get("implications", []), 1):
        impl_lines += f"{i}. **{imp['principle']}** â€” {imp['detail']}\n"

    # Market data
    market_str = "; ".join(intel.get("market_projections", ["N/A"]))
    gartner_str = intel.get("gartner_prediction", "N/A")

    v2 = f"""# Agent Orchestration Strategy v2 â€” Merged Intelligence Edition

**Version:** 2.0
**Generated:** {now}
**Source v1:** `artifacts/generated/agent_strategy.md`
**Research Feed:** `artifacts/research_summary.md`
**Generator:** `self_modify_test.py`

---

## 1. Market Context (from Research)

**Market Projection:** {market_str}
**Gartner Forecast:** {gartner_str}

---

## 2. Protocol Landscape (Upgraded)

| Protocol | Scope | Key Backers | Status |
|----------|-------|-------------|--------|
{proto_rows}
### v2 Recommendation

AetherPro should adopt **MCP v1.3** as the primary context-sharing backbone (leveraging pruning,
summary caching, and semantic chunking), while implementing **A2A** for peer-to-peer agent
messaging. The **OASF** RFC should be tracked for future lifecycle governance compliance.

---

## 3. Coordination Models (from v1 + Research Upgrade)

| Model | Use Case | Tradeoff |
|-------|----------|----------|
{coord_rows}
### v2 Recommendation

Based on research findings, the **Hybrid (Star + Mesh)** model is the production consensus for
2026. AetherPro's MCPFabric.space is already aligned with this pattern. Priority: implement
the **Mother Agent (Orchestrator)** pattern with vertical agent specialization.

---

## 4. Task Delegation Protocol (from v1)

{deleg_lines}
### v2 Enhancement

Add a **FinOps gate** between steps 3 and 4: the orchestrator should evaluate cost-tier routing
(frontier model for planning, cheaper models for execution) before dispatching sub-tasks.
This aligns with the **Plan-and-Execute** pattern yielding ~90% cost reduction.

---

## 5. Tool Selection Heuristics (from v1)

{heuristic_lines}
### v2 Enhancement

Add heuristic #6: **Cost-Aware Routing** â€” Route tool calls through the Model Fleet Manager's
business policy engine. Free-tier users get local/cached results; Pro-tier gets real-time
external calls. This maps directly to the Fleet Manager's `POST /fleet/select_model` API.

---

## 6. Memory Architecture (from v1)

Tiers:
{memory_lines}
### v2 Enhancement (from Research)

Integrate **MCP v1.3 context engineering** features:
- **Semantic chunking** for long-term memory retrieval
- **Summary caching** to avoid redundant LLM calls for repeated context
- **Context pruning** at the session level (addresses the 30-50% failure rate in long-running swarms)
- Map to Triad Intelligence's three-layer architecture (PostgreSQL â†’ Redis â†’ in-memory)

---

## 7. Failure Recovery (from v1)

{recovery_lines}
### v2 Enhancement

Add **Level 5 â€” Durable Execution** (from research): adopt Temporal-style workflow persistence
for critical multi-agent pipelines. If a node fails mid-workflow, the orchestrator replays from
the last durable checkpoint rather than restarting from scratch. This is the pattern OpenAI uses
for Codex in production.

---

## 8. Architecture Evolution (from Research)

{arch_lines}
### v2 Recommendation

AetherPro is well-positioned for the hybrid approach. The Model Fleet Manager already implements
heterogeneous model routing (VRAM arbitration, business policy as code). Next milestone:
formalize the **LLM Skills** layer as composable, shareable capability modules registered in
MCPFabric.space's Universal Skills MCP Server.

---

## 9. Competitive Landscape

| Platform | Category | Strength |
|----------|----------|----------|
{player_rows}
### v2 Positioning

AetherPro differentiates by combining **sovereign infrastructure** (OVHcloud, no hyperscaler
lock-in) with **composable agent architecture** (MCP + A2A + Fleet Manager). The closest
comparison is a self-hosted LangGraph + Temporal stack, but with integrated GPU fleet management
and identity governance (Passport-Pro).

---

## 10. Strategic Implications

{impl_lines}
### v2 Action Items

1. **Ship MCP v1.3 integration** in MCPFabric.space (Q1 2026)
2. **Implement Mother Agent orchestrator** with vertical agent spawning
3. **Deploy FinOps routing** in Model Fleet Manager v1
4. **Formalize LLM Skills registry** as composable modules
5. **Adopt Temporal** for durable multi-agent workflow execution
6. **Track OASF RFC** for future compliance

---

*v2 Strategy generated by `self_modify_test.py` â€” merging v1 patterns with 2026 research intelligence*
"""
    return v2


# â”€â”€ Phase 1D: Self-Modification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

APPENDED_FUNCTION_CODE = '''

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SELF-APPENDED FUNCTION â€” Added by self_modify_test.py during Phase 1D
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def log_merge_result():
    """
    Self-appended function that logs the merge result.
    This function was dynamically added to the script during execution,
    then the script re-invoked itself with --phase2 to run it.
    """
    import json
    from datetime import datetime, timezone

    report_path = os.path.join(
        os.path.dirname(os.path.abspath(__file__)),
        "artifacts", "generated", "self_modify_report.json"
    )

    # Read existing partial report
    if os.path.exists(report_path):
        with open(report_path, "r") as f:
            report = json.load(f)
    else:
        report = {}

    # Add phase 2 data
    report["phase2_executed"] = True
    report["phase2_timestamp"] = datetime.now(timezone.utc).isoformat()
    report["self_modification_verified"] = True
    report["appended_function"] = "log_merge_result"
    report["message"] = (
        "Self-modification successful. This function was appended to the script "
        "during Phase 1D, then executed via --phase2 re-invocation. "
        "The agent can read, merge, self-modify, and re-execute autonomously."
    )

    # Write final report
    with open(report_path, "w") as f:
        json.dump(report, f, indent=2, default=str)

    print("=" * 60)
    print("  PHASE 2 â€” SELF-APPENDED FUNCTION EXECUTED")
    print("=" * 60)
    print(f"  Report updated: {report_path}")
    print(f"  Before hash:    {report.get('before_sha256', 'N/A')[:16]}...")
    print(f"  After hash:     {report.get('after_sha256', 'N/A')[:16]}...")
    print(f"  Lines added:    {report.get('line_count_delta', 'N/A')}")
    print(f"  Success:        {report.get('success', False)}")
    print("=" * 60)

    return report


if __name__ == "__main__" and "--phase2" in sys.argv:
    log_merge_result()
'''


def self_modify_and_reexecute():
    """
    Append log_merge_result() to this script, then re-invoke with --phase2.
    Returns (before_hash, after_hash, line_delta, phase2_success).
    """
    # Snapshot before
    before_hash = sha256_of_file(SCRIPT_PATH)
    before_lines = line_count(SCRIPT_PATH)

    print(f"\nğŸ”§ Self-Modification:")
    print(f"  Script:       {SCRIPT_PATH}")
    print(f"  Before hash:  {before_hash[:16]}...")
    print(f"  Before lines: {before_lines}")

    # Append the new function
    with open(SCRIPT_PATH, "a") as f:
        f.write(APPENDED_FUNCTION_CODE)

    # Snapshot after
    after_hash = sha256_of_file(SCRIPT_PATH)
    after_lines = line_count(SCRIPT_PATH)
    line_delta = after_lines - before_lines

    print(f"  After hash:   {after_hash[:16]}...")
    print(f"  After lines:  {after_lines}")
    print(f"  Lines added:  +{line_delta}")
    print(f"  Modified:     {'âœ… YES' if before_hash != after_hash else 'âŒ NO'}")

    # Write partial report (phase 2 will complete it)
    partial_report = {
        "script": SCRIPT_PATH,
        "before_sha256": before_hash,
        "after_sha256": after_hash,
        "before_line_count": before_lines,
        "after_line_count": after_lines,
        "line_count_delta": line_delta,
        "self_modified": before_hash != after_hash,
        "phase1_timestamp": datetime.now(timezone.utc).isoformat(),
        "v2_strategy_path": V2_OUTPUT_PATH,
        "success": False,  # Will be set True by phase 2
    }
    write_file(REPORT_PATH, json.dumps(partial_report, indent=2, default=str))

    # Re-execute with --phase2
    print(f"\nğŸ”„ Re-executing self with --phase2...")
    result = subprocess.run(
        [sys.executable, SCRIPT_PATH, "--phase2"],
        capture_output=True, text=True, timeout=30
    )
    print(result.stdout)
    if result.stderr:
        print(f"  STDERR: {result.stderr}")

    phase2_ok = result.returncode == 0

    # Update report with final status
    partial_report["success"] = phase2_ok
    partial_report["phase2_returncode"] = result.returncode
    write_file(REPORT_PATH, json.dumps(partial_report, indent=2, default=str))

    return before_hash, after_hash, line_delta, phase2_ok


# â”€â”€ Main Execution â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    """Phase 1: Read â†’ Extract â†’ Merge â†’ Self-Modify â†’ Re-Execute."""
    print("=" * 60)
    print("  SELF-MODIFY TEST â€” Phase 1")
    print("=" * 60)

    # Step 1: Read source files
    print("\nğŸ“– Reading source files...")
    strategy_text = read_file(STRATEGY_PATH)
    research_text = read_file(RESEARCH_PATH)
    print(f"  agent_strategy.md:  {len(strategy_text):,} chars, {strategy_text.count(chr(10))} lines")
    print(f"  research_summary.md: {len(research_text):,} chars, {research_text.count(chr(10))} lines")

    # Step 2: Extract patterns and intelligence
    print("\nğŸ” Extracting coordination patterns from v1 strategy...")
    patterns = extract_coordination_patterns(strategy_text)
    for key, val in patterns.items():
        count = len(val) if isinstance(val, list) else 1
        print(f"  {key}: {count} items extracted")

    print("\nğŸ” Extracting protocols & market data from research...")
    intel = extract_research_intel(research_text)
    for key, val in intel.items():
        count = len(val) if isinstance(val, list) else 1
        print(f"  {key}: {count} items extracted")

    # Step 3: Generate v2 strategy
    print("\nğŸ“ Generating v2_strategy.md...")
    v2_content = generate_v2_strategy(patterns, intel)
    write_file(V2_OUTPUT_PATH, v2_content)
    v2_lines = v2_content.count("\n")
    v2_hash = sha256_of_file(V2_OUTPUT_PATH)
    print(f"  Written: {V2_OUTPUT_PATH}")
    print(f"  Size:    {len(v2_content):,} chars, {v2_lines} lines")
    print(f"  SHA-256: {v2_hash[:16]}...")

    # Step 4: Self-modify and re-execute
    before_hash, after_hash, line_delta, phase2_ok = self_modify_and_reexecute()

    # Final summary
    print("\n" + "=" * 60)
    print("  SELF-MODIFY TEST â€” FINAL SUMMARY")
    print("=" * 60)
    print(f"  v1 Strategy Read:    âœ…")
    print(f"  Research Read:       âœ…")
    print(f"  Patterns Extracted:  âœ… ({len(patterns)} categories)")
    print(f"  Intel Extracted:     âœ… ({len(intel)} categories)")
    print(f"  v2 Strategy Written: âœ… ({v2_lines} lines)")
    print(f"  Self-Modified:       {'âœ…' if before_hash != after_hash else 'âŒ'}")
    print(f"  Phase 2 Executed:    {'âœ…' if phase2_ok else 'âŒ'}")
    print(f"  Report Written:      âœ… ({REPORT_PATH})")
    print(f"  Overall:             {'âœ… ALL PASSED' if phase2_ok else 'âŒ PHASE 2 FAILED'}")
    print("=" * 60)


if __name__ == "__main__" and "--phase2" not in sys.argv:
    main()
